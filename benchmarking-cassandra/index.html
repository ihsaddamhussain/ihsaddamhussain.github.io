<!DOCTYPE html>
<html lang="en">
  <head>
  <title>Benchmarking Apache Cassandra with Rust | Piotr Kołaczkowski</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Performance of a database system depends on many factors: hardware, configuration, database schema, amount of data, workload type, network latency, and many ...">
  <meta name="author" content="Piotr Kołaczkowski">
  <meta name="generator" content="Jekyll v4.1.1">
  <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-PBJQD2M');</script>
<!-- End Google Tag Manager -->

  <link rel="canonical" href="/benchmarking-cassandra/">
  
  <link rel="stylesheet" href="/assets/css/index.css">
  
  <link rel="stylesheet" href="/assets/css/classes.css">
  <link rel="stylesheet" href="/assets/css/sidebar.css" media="screen and (min-width: 70em)">
  <link rel="alternate" href="/feed.xml" type="application/atom+xml" title="Piotr Kołaczkowski">
  
  
  <script defer src="/assets/node_modules/chart.js/dist/Chart.min.js"></script>
</head>
<body>
  <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PBJQD2M"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
  <header class="icons">
    
      <a href="/" class="title">Piotr Kołaczkowski</a>
    
    
      
  <nav>
  <a aria-label="Home" href="/" ><svg aria-hidden="true" class="hidden"><use xlink:href="/assets/fontawesome/icons.svg#home"></use></svg><span aria-hidden="true" >Home</span></a>
  <a aria-label="About" href="/about/" ><svg aria-hidden="true" class="hidden"><use xlink:href="/assets/fontawesome/icons.svg#address-card"></use></svg><span aria-hidden="true" >About</span></a>
  
  </nav>


      
  <nav>
  <a aria-label="Mail" href="mailto:pkolaczk@gmail.com" ><svg aria-hidden="true" ><use xlink:href="/assets/fontawesome/icons.svg#envelope"></use></svg><span aria-hidden="true" class="hidden">Mail</span></a>
  <a aria-label="Github" href="https://github.com/pkolaczk" ><svg aria-hidden="true" ><use xlink:href="/assets/fontawesome/icons.svg#github"></use></svg><span aria-hidden="true" class="hidden">Github</span></a>
  <a aria-label="LinkedIn" href="https://www.linkedin.com/in/pkolaczk" ><svg aria-hidden="true" ><use xlink:href="/assets/fontawesome/icons.svg#linkedin"></use></svg><span aria-hidden="true" class="hidden">LinkedIn</span></a>
  <a aria-label="RSS" href="/feed.xml" ><svg aria-hidden="true" ><use xlink:href="/assets/fontawesome/icons.svg#rss"></use></svg><span aria-hidden="true" class="hidden">RSS</span></a>
  
  </nav>


    
    
      <div class="hidden description">Blog on programming, optimization and performance analysis</div>
    

  </header>

  <article>
  <header>
  
  <h1><a href="/benchmarking-cassandra/">Benchmarking Apache Cassandra with Rust</a></h1><time datetime="2020-10-05T00:00:00+02:00">October 05, 2020</time>
</header>

  <p>Performance of a database system depends on many factors: hardware, configuration, 
database schema, amount of data, workload type, network latency, and many others.
Therefore, one typically can’t tell the actual performance of such system without
first measuring it. In this blog post I’m describing how to build a benchmarking tool
for Apache Cassandra from scratch in Rust and how to avoid many pitfalls. 
The techniques I show are applicable to any system with an async API.</p>

<!--more-->

<p><a href="https://cassandra.apache.org/">Apache Cassandra</a> is a popular, scalable, distributed, open-source database system.
It comes with its own benchmarking tool <code class="language-plaintext highlighter-rouge">cassandra-stress</code> that can issue queries in parallel and measure
throughtput and response times. It offers not just a few built-in standard benchmarks, but also allows defining 
custom schemas and workloads, making it really versatile. So why write another one?</p>

<p>Being written in Java, <code class="language-plaintext highlighter-rouge">cassanda-stress</code> has a few downsides:</p>

<ul>
  <li>
    <p>It consumes a significant amount of CPU and RAM resources by itself. This makes it a bad idea to
run it on the same machine as the database server, because the amount of resources available to the server
would be strongly reduced. This problem obviously exists for just <em>any</em> benchmarking tool regardless of its performance, 
but I was really surprised to find that <code class="language-plaintext highlighter-rouge">cassandra-stress</code> often takes about the same amount of CPU time as the server 
it benchmarks, essentially halving the CPU time available to Cassandra. This also means that even when running it on a separate computer, 
you need to make sure it is as powerful as the system under test. Or in case of bigger clusters - you need a decent cluster just for the client machines.</p>
  </li>
  <li>
    <p>It requires warmup for the JVM. This is a problem of all JVM-based benchmarking tools (including 
excellent benchmarking frameworks like JMH). You can’t run a test for a second or even a few secods, because
initial measurements are inaccurate and need to be thrown-away. This problem might be considered a minor annoyance, 
but it seriously gets in a way if you ever wanted to measure the effect of JVM warmup on the server side performance 
(which happens e.g. after restarting the server). In this case you can’t tell the effects of the warmup on the server 
side from the effects on the client side.</p>
  </li>
  <li>
    <p>JVM that runs the benchmark tool and its GC are an additional source of unpredictable delays. 
The reported latency analysis is affected by the delays happening on the client, so these ideally should be as 
low as possible. Modern Java GCs claim sub-10 ms pause times, and I find them too high for benchmarking a system 
that aims for sub millisecond average response-times.</p>
  </li>
</ul>

<p>A natively compiled, GC-less language like C, C++ or Rust addresses all of these issues.
Let’s see how we can write a benchmarking tool in Rust.</p>

<h1 id="connecting-to-cassandra">Connecting to Cassandra</h1>
<p>Before we can issue any queries, we need to establish a connection to the database and obtain a session. 
To access Cassandra, we’ll use <a href="https://docs.rs/cassandra-cpp/0.15.1/cassandra_cpp/">cassandra_cpp</a> 
crate which is a Rust wrapper over <a href="https://docs.datastax.com/en/developer/cpp-driver/index.html">the official Cassandra driver for C++</a> 
from <a href="https://www.datastax.com">DataStax</a>. There exist other third-party drivers developed natively in Rust from scratch, but at the time of writing this post,
they weren’t production ready.</p>

<p>Installing the driver on Ubuntu is straightforward:</p>
<pre>
sudo apt install libuv1 libuv1-dev
sudo dpkg -i cassandra-cpp-driver_2.15.3-1_amd64.deb
sudo dpkg -i cassandra-cpp-driver-dev_2.15.3-1_amd64.deb
</pre>

<p>Then we need to add <code class="language-plaintext highlighter-rouge">cassandra_cpp</code> dependency to <code class="language-plaintext highlighter-rouge">Cargo.toml</code>:</p>

<div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="py">cassandra-cpp</span> <span class="p">=</span> <span class="s">"0.15.1"</span>
</code></pre></div></div>

<p>Configuring the connection is performed through <code class="language-plaintext highlighter-rouge">Cluster</code> type:</p>
<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">cassandra_cpp</span><span class="p">::</span><span class="o">*</span><span class="p">;</span>

<span class="k">let</span> <span class="k">mut</span> <span class="n">cluster</span> <span class="o">=</span> <span class="nn">Cluster</span><span class="p">::</span><span class="nf">default</span><span class="p">();</span>
<span class="n">cluster</span><span class="nf">.set_contact_points</span><span class="p">(</span><span class="s">"localhost"</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
<span class="n">cluster</span><span class="nf">.set_core_connections_per_host</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
<span class="n">cluster</span><span class="nf">.set_max_connections_per_host</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>    
<span class="n">cluster</span><span class="nf">.set_queue_size_io</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
<span class="n">cluster</span><span class="nf">.set_num_threads_io</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
<span class="n">cluster</span><span class="nf">.set_connect_timeout</span><span class="p">(</span><span class="nn">time</span><span class="p">::</span><span class="nn">Duration</span><span class="p">::</span><span class="nf">seconds</span><span class="p">(</span><span class="mi">5</span><span class="p">));</span>
<span class="n">cluster</span><span class="nf">.set_load_balance_round_robin</span><span class="p">();</span>
</code></pre></div></div>

<p>Finally, we can connect:</p>
<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">session</span> <span class="o">=</span> <span class="k">match</span> <span class="n">cluster</span><span class="nf">.connect</span><span class="p">()</span> <span class="p">{</span>
  <span class="nf">Ok</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="p">,</span>
  <span class="nf">Err</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">{</span>
      <span class="nd">eprintln!</span><span class="p">(</span><span class="s">"error: Failed to connect to Cassandra: {}"</span><span class="p">,</span> <span class="n">e</span><span class="p">);</span>
      <span class="nf">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h1 id="just-a-loop">Just a Loop</h1>
<p>Now that we have the <code class="language-plaintext highlighter-rouge">session</code>, we can issue queries.
How hard could writing a database benchmark be? It is just sending queries in a loop and measuring how long they take, isn’t it?
For simplicity, let’s assume there already exists a table <code class="language-plaintext highlighter-rouge">test</code> in <code class="language-plaintext highlighter-rouge">keyspace1</code> with the following schema:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">keyspace1</span><span class="p">.</span><span class="n">test</span><span class="p">(</span><span class="n">pk</span> <span class="nb">BIGINT</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span> <span class="n">col</span> <span class="nb">BIGINT</span><span class="p">);</span>
</code></pre></div></div>

<p>Let’s issue some reads from this table and measure how long they took:</p>
<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">std</span><span class="p">::</span><span class="nn">time</span><span class="p">::{</span><span class="n">Duration</span><span class="p">,</span> <span class="n">Instant</span><span class="p">};</span>

<span class="k">let</span> <span class="n">session</span> <span class="o">=</span> <span class="c">// ... setup the session</span>
<span class="k">let</span> <span class="n">count</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">;</span>
<span class="k">let</span> <span class="n">start</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
<span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">count</span> <span class="p">{</span>
  <span class="n">session</span>
    <span class="nf">.execute</span><span class="p">(</span><span class="o">&amp;</span><span class="nd">stmt!</span><span class="p">(</span><span class="s">"SELECT * FROM keyspace1.test WHERE pk = 1"</span><span class="p">))</span>
    <span class="nf">.wait</span><span class="p">()</span>
    <span class="nf">.unwrap</span><span class="p">();</span>
<span class="p">}</span>
<span class="k">let</span> <span class="n">end</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
<span class="nd">println!</span><span class="p">(</span>
    <span class="s">"Throughput: {:.1} request/s"</span><span class="p">,</span>
    <span class="mf">1000000.0</span> <span class="o">*</span> <span class="n">count</span> <span class="k">as</span> <span class="nb">f64</span> <span class="o">/</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="nf">.as_micros</span><span class="p">()</span> <span class="k">as</span> <span class="nb">f64</span>
<span class="p">);</span>

</code></pre></div></div>

<p>I bet you’ve seen similar benchmarking code in some benchmarks on the Internet.
I’ve seen results from code like this being used to justify a choice of one database system over another.
Unfortunately, this simple code has a few very serious issues and can lead to incorrect conclusions 
about performance of the system:</p>

<ol>
  <li>
    <p>The loop performs only one request at a time. In case of systems like Apache Cassandra which are optimised
to handle <em>many thousands</em> of parallel requests, this leaves most of the available computing resources idle.
Most (all?) modern CPUs have multiple cores. Hard drives also <a href="/disk-parallelism/">benefit from parallel access</a>.
Additionally, there is non-zero network latency for sending the request to the server and 
sending the response back to the client. Even if running this client code on the same computer, there is non-zero time needed 
for the operating system to deliver the data from one process to another over the loopback. 
During that time, the server has literally <em>nothing to do</em>. The result throughput you’ll get from such a naive benchmark loop 
will be significantly lower than the server is really capable of.</p>
  </li>
  <li>
    <p>Sending a single query at a time precludes the driver from automatically 
batching multiple requests. Batching can improve the network bandwidth by using a more 
efficient data representation and can reduce the number of syscalls, e.g. by writing
many requests to the network socket at once. Reading requests from the socket on the server side 
is also much more efficient if there are many available in the socket buffer.</p>
  </li>
  <li>
    <p>The code doesn’t use prepared statements. Many database systems, not only Cassandra, but also many traditional relational 
database systems, have this feature for a reason: parsing and planning a query can be a substantial amount of work, 
and it is makes sense to do it only once.</p>
  </li>
  <li>
    <p>The code is reading the same row over and over again. Depending on what you wish to measure this could be a good or a bad thing.
In this case, the database system would cache the data fully and serve it from RAM, so you might actually overestimate the performance, 
because real workloads rarely fetch a single row in a loop. On the other hand, such test would make some sense if you deliberately
want to test the happy-path performance of the cache layer.</p>
  </li>
</ol>

<p>As a result, the reported throughput is abysmally poor:</p>
<pre>
Throughput: 2279.7 request/s
</pre>

<h1 id="prepared-statements">Prepared Statements</h1>
<p>The problems #3 and #4 are the easiest to solve. Let’s change the code to use a prepared statement, and let’s introduce a parameter
so we’re not fetching the same row all the time:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">cassandra_cpp</span><span class="p">::</span><span class="o">*</span><span class="p">;</span>
<span class="k">use</span> <span class="nn">std</span><span class="p">::</span><span class="nn">time</span><span class="p">::{</span><span class="n">Duration</span><span class="p">,</span> <span class="n">Instant</span><span class="p">};</span>

<span class="k">let</span> <span class="n">session</span> <span class="o">=</span> <span class="c">// ... setup the session</span>
<span class="k">let</span> <span class="n">statement</span> <span class="o">=</span> <span class="n">session</span>
    <span class="nf">.prepare</span><span class="p">(</span><span class="s">"SELECT * FROM keyspace1.test WHERE pk = ?"</span><span class="p">)</span><span class="o">?</span>
    <span class="nf">.wait</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
<span class="k">let</span> <span class="n">count</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">;</span>
<span class="k">let</span> <span class="n">start</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
<span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">count</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">statement</span> <span class="o">=</span> <span class="n">statement</span><span class="nf">.bind</span><span class="p">();</span>
    <span class="n">statement</span><span class="nf">.bind</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span> <span class="k">as</span> <span class="nb">i64</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="n">session</span><span class="nf">.execute</span><span class="p">(</span><span class="o">&amp;</span><span class="n">statement</span><span class="p">)</span><span class="nf">.wait</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">();</span>
<span class="p">}</span>
<span class="k">let</span> <span class="n">end</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
<span class="nd">println!</span><span class="p">(</span>
    <span class="s">"Throughput: {:.1} request/s"</span><span class="p">,</span>
    <span class="mf">1000000.0</span> <span class="o">*</span> <span class="n">count</span> <span class="k">as</span> <span class="nb">f64</span> <span class="o">/</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="nf">.as_micros</span><span class="p">()</span> <span class="k">as</span> <span class="nb">f64</span>
<span class="p">);</span>
</code></pre></div></div>

<p>Unfortunately, the performance is still extremely low.</p>
<pre>
Throughput: 2335.9 request/s
</pre>

<h1 id="going-async">Going <code class="language-plaintext highlighter-rouge">async</code></h1>
<p>To fix the problems #1 and #2, we need to send more than one query at a time.
In the codes above we’re calling <code class="language-plaintext highlighter-rouge">wait()</code> on the futures returned from the driver 
and that call is blocking. And because our program is single-threaded, it can’t do anything 
else while being blocked.</p>

<p>There are two approaches we can take:</p>

<ul>
  <li>
    <p>Launch many threads and let each thread run its own loop coded in the way as shown above.
I tried this, and you have to believe this approach requires <em>hundreds</em> of threads to get a decent
performance from a single-node Cassandra cluster. I won’t show it here, because I don’t prefer this solution – it feels 
unnatural when the driver offers excellent async capabilities
(but feel free to drop a comment and share your experience if you coded it by yourself). 
More importantly, this approach is susceptible to coordinated omission, where a single slow requests 
(e.g. blocked by server-side GC) could delay sending a bunch of other requests, hence making the reported
response times too optimistic.</p>
  </li>
  <li>
    <p>Use async programming model: don’t block immediately on the returned future after spawning a single request, 
but spawn many requests and collect results asynchronously when they are ready. This way we’re making sending 
requests independent from each other, thus avoiding coordinated omission.
It is easy to do with <code class="language-plaintext highlighter-rouge">cassandra_cpp</code> and Cassandra C++ driver because internally it also uses that style.
You can notice that almost all the functions of the driver 
return futures that are compatible with Rust’s <code class="language-plaintext highlighter-rouge">async</code>/<code class="language-plaintext highlighter-rouge">await</code> feature.</p>
  </li>
</ul>

<p>In order to be able to use async functions at all, first we need to initialize an async runtime.
I decided to use a very popular crate <a href="https://tokio.rs/">tokio</a>. Installation is adding just the following line 
to <code class="language-plaintext highlighter-rouge">Cargo.toml</code>:</p>

<div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">tokio</span> <span class="o">=</span> <span class="p">{</span> <span class="py">version</span> <span class="p">=</span> <span class="s">"0.2"</span><span class="p">,</span> <span class="py">features</span> <span class="p">=</span> <span class="nn">["full"]</span> <span class="p">}</span>
</code></pre></div></div>

<p>Now we can annotate the main function as <code class="language-plaintext highlighter-rouge">async</code>, replace <code class="language-plaintext highlighter-rouge">wait</code> with <code class="language-plaintext highlighter-rouge">await</code>, and call <code class="language-plaintext highlighter-rouge">tokio::spawn</code> 
to launch the requests. Although <code class="language-plaintext highlighter-rouge">await</code> looks like blocking, it doesn’t block the calling thread, but 
allows it to move on to the next task.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[tokio::main]</span>
<span class="k">async</span> <span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="nn">cassandra_cpp</span><span class="p">::</span><span class="n">Result</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">cluster</span> <span class="o">=</span> <span class="nn">Cluster</span><span class="p">::</span><span class="nf">default</span><span class="p">();</span>
    <span class="c">// ... configure cluster</span>
    <span class="k">let</span> <span class="n">session</span> <span class="o">=</span> <span class="n">cluster</span><span class="nf">.connect_async</span><span class="p">()</span><span class="py">.await</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">statement</span> <span class="o">=</span> <span class="n">session</span>
        <span class="nf">.prepare</span><span class="p">(</span><span class="s">"SELECT * FROM keyspace1.test WHERE pk = ?"</span><span class="p">)</span><span class="o">?</span>
        <span class="py">.await</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">count</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">start</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
    <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">count</span> <span class="p">{</span>
        <span class="k">let</span> <span class="k">mut</span> <span class="n">statement</span> <span class="o">=</span> <span class="n">statement</span><span class="nf">.bind</span><span class="p">();</span>
        <span class="n">statement</span><span class="nf">.bind</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span> <span class="k">as</span> <span class="nb">i64</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nf">spawn</span><span class="p">(</span><span class="k">async</span> <span class="p">{</span>
            <span class="k">let</span> <span class="n">result</span> <span class="o">=</span> <span class="n">session</span><span class="nf">.execute</span><span class="p">(</span><span class="o">&amp;</span><span class="n">statement</span><span class="p">);</span>
            <span class="n">result</span><span class="py">.await</span><span class="nf">.unwrap</span><span class="p">();</span>
        <span class="p">});</span>
    <span class="p">}</span>
    <span class="k">let</span> <span class="n">end</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
    <span class="nd">println!</span><span class="p">(</span>
        <span class="s">"Throughput: {:.1} request/s"</span><span class="p">,</span>
        <span class="mf">1000000.0</span> <span class="o">*</span> <span class="n">count</span> <span class="k">as</span> <span class="nb">f64</span> <span class="o">/</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="nf">.as_micros</span><span class="p">()</span> <span class="k">as</span> <span class="nb">f64</span>
    <span class="p">);</span>
    <span class="nf">Ok</span><span class="p">(())</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Unfortunately, this doesn’t compile, because our friend borrow-checker
correctly notices that the async code inside of the loop can live longer than the 
<code class="language-plaintext highlighter-rouge">main()</code> function and its local variables such as <code class="language-plaintext highlighter-rouge">i</code>, <code class="language-plaintext highlighter-rouge">session</code> and <code class="language-plaintext highlighter-rouge">statement</code>:</p>

<pre>
error[E0373]: async block may outlive the current function, but it borrows `i`, which is owned by the current function
262 |           tokio::spawn(async {
...
help: to force the async block to take ownership of `i` (and any other referenced variables), use the `move` keyword

error[E0373]: async block may outlive the current function, but it borrows `statement`, which is owned by the current function
help: to force the async block to take ownership of `statement` (and any other referenced variables), use the `move` keyword

error[E0373]: async block may outlive the current function, but it borrows `session`, which is owned by the current function
help: to force the async block to take ownership of `session` (and any other referenced variables), use the `move` keyword
</pre>

<p>The compiler advices us to use <code class="language-plaintext highlighter-rouge">move</code> to move these shared variables into the async code:</p>
<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c">// ...</span>
    <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">count</span> <span class="p">{</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nf">spawn</span><span class="p">(</span><span class="k">async</span> <span class="k">move</span> <span class="p">{</span>
            <span class="c">//...</span>
   
</code></pre></div></div>

<p>Fortunately, the problem with the loop counter <code class="language-plaintext highlighter-rouge">i</code> and <code class="language-plaintext highlighter-rouge">statement</code> is gone now.
But that still doesn’t work for <code class="language-plaintext highlighter-rouge">session</code>:</p>
<pre>
error[E0382]: use of moved value: `session`
   --&gt; src/main.rs:262:33
    |
255 |       let session = cluster.connect_async().await.unwrap();
    |           ------- move occurs because `session` has type `cassandra_cpp::Session`, which does not implement the `Copy` trait
...
262 |           tokio::spawn(async move {
    |  _________________________________^
263 | |             let result = session.execute(&amp;statement);
    | |                          ------- use occurs due to use in generator
264 | |             result.await.unwrap();
265 | |         });
    | |_________^ value moved here, in previous iteration of loop
</pre>

<p>This is quite obvious – we’re spawning more than one async task here, but because <code class="language-plaintext highlighter-rouge">session</code> is not copyable,
there can only exist one of each. Of course, we don’t want multiple sessions or statements here – we need a single one shared
among all the tasks. But how to pass only <code class="language-plaintext highlighter-rouge">session</code> by reference but still use <code class="language-plaintext highlighter-rouge">move</code> for passing the loop
counter <code class="language-plaintext highlighter-rouge">i</code> and <code class="language-plaintext highlighter-rouge">statement</code>?</p>

<p>Let’s take the reference to <code class="language-plaintext highlighter-rouge">session</code> before the loop – references are copyable:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c">// ...</span>
    <span class="k">let</span> <span class="n">session</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">session</span><span class="p">;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">count</span> <span class="p">{</span>
        <span class="c">// ...</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nf">spawn</span><span class="p">(</span><span class="k">async</span> <span class="k">move</span> <span class="p">{</span>
            <span class="c">// ...</span>
</code></pre></div></div>

<p>But this brings us back to the first problem of insufficient lifetime, though:</p>
<pre>
error[E0597]: `session` does not live long enough
   --&gt; src/main.rs:262:19
    |
262 |       let session = &session;
    |                     ^^^^^^^^ borrowed value does not live long enough
...
265 |           tokio::spawn(async move {
    |  ______________________-
266 | |             let result = session.execute(&amp;statement);
267 | |             result.await.unwrap();
268 | |         });
    | |_________- argument requires that `session` is borrowed for `'static`
...
276 |   }
    |   - `session` dropped here while still borrowed

</pre>

<p>So it looks like we can’t pass the session by move, 
because we want sharing, but we also can’t pass it by reference because the 
session doesn’t live long enough.</p>

<h1 id="scopes">Scopes?</h1>
<p>In <a href="/multiple-threadpools-rust/">one of the earlier blog bosts</a> I showed how this problem
can be solved by using scoped threads. The concept of scope allows to force
all background tasks to finish before the shared variables are dropped.</p>

<p>Unfortunately, I haven’t found anything like scopes inside of the <code class="language-plaintext highlighter-rouge">tokio</code> crate. 
A search reveals a <a href="https://github.com/tokio-rs/tokio/issues/2596">ticket</a>, but it has been closed
and the conclusion is a bit disappointing:</p>

<blockquote>
  <p>As @Matthias247 pointed out, one should be able to establish scopes at any point. 
However, there is no way to enforce the scope without blocking the thread. 
The best we can do towards enforcing the scope is to panic when used “incorrectly”. 
This is the strategy @Matthias247 has taken in his PRs. However, dropping adhoc is currently a key async rust pattern. 
I think this prohibits pancing when dropping a scope that isn’t 100% complete. If we do this, using a scope within a select! would lead to panics.
We are at an impasse. Maybe if AsyncDrop lands in Rust then we can investigate this again. Until then, we have no way forward, so I will close this. 
It is definitely an unfortunate outcome.</p>
</blockquote>

<p>Of course, if you are fine with blocking the thread on scope exit, you can use the 
<a href="https://docs.rs/tokio-scoped/0.1.0/tokio_scoped/">tokio_scoped</a> crate.</p>

<h1 id="arc">ARC</h1>
<p>The lifetime problem can be also solved with automatic reference counting. 
Let’s wrap the <code class="language-plaintext highlighter-rouge">session</code> and <code class="language-plaintext highlighter-rouge">statement</code> in <code class="language-plaintext highlighter-rouge">Arc</code>. <code class="language-plaintext highlighter-rouge">Arc</code> will keep the shared session and statement
live as long as there exists at least one unfinished task:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c">// ...</span>
    <span class="k">let</span> <span class="n">session</span> <span class="o">=</span> <span class="nn">Arc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">session</span><span class="p">);</span>
    <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">count</span> <span class="p">{</span>
        <span class="k">let</span> <span class="k">mut</span> <span class="n">statement</span> <span class="o">=</span> <span class="n">statement</span><span class="nf">.bind</span><span class="p">();</span>
        <span class="n">statement</span><span class="nf">.bind</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span> <span class="k">as</span> <span class="nb">i64</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
        <span class="k">let</span> <span class="n">session</span> <span class="o">=</span> <span class="n">session</span><span class="nf">.clone</span><span class="p">();</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nf">spawn</span><span class="p">(</span><span class="k">async</span> <span class="k">move</span> <span class="p">{</span>
            <span class="c">// ...</span>

</code></pre></div></div>

<p>This compiles fine and it wasn’t even that hard! Let’s run it:</p>
<pre>
thread 'tokio-runtime-worker' panicked at 'called `Result::unwrap()` on an `Err` value: 
Error(CassError(LIB_REQUEST_QUEUE_FULL, "The request queue has reached capacity"), State { next_error: None, backtrace: InternalBacktrace { backtrace: None } })', src/main.rs:271:26
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
</pre>

<p>We submitted 100000 async queries all at once and the client driver’s queue can’t hold so many. 
Let’s do a quick temporary workaround: lower the <code class="language-plaintext highlighter-rouge">count</code> to 1000.
The benchmark finishes fine now:</p>

<pre>
Throughput: 3095975.2 request/s
</pre>

<p>But is the result correct? Is Apache Cassandra really so fast? I’d really love to use a database that can do 3+ mln queries per second on a developer’s laptop,
but unfortunately this isn’t the case. The benchmark is still incorrect. Now we don’t wait at all for the results to come back from the database. 
The benchmark submits the queries to the driver’s queue as fast as possible and then it immediately considers its job done. So we only measured how fast we
can send the queries to the local driver’s queue (not even how fast we can push them to the database server).</p>

<h1 id="waiting-for-everything-to-finish">Waiting for Everything to Finish</h1>
<p>Look at what we’re doing with the result of the query:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            <span class="c">// ...</span>
            <span class="k">let</span> <span class="n">result</span> <span class="o">=</span> <span class="n">session</span><span class="nf">.execute</span><span class="p">(</span><span class="o">&amp;</span><span class="n">statement</span><span class="p">);</span>
            <span class="n">result</span><span class="py">.await</span><span class="nf">.unwrap</span><span class="p">();</span>        
        <span class="p">});</span>
</code></pre></div></div>

<p>The problem is: we’re doing nothing! After unwrapping, we’re just throwing the result away. 
Although the <code class="language-plaintext highlighter-rouge">await</code> might look like we were waiting for the result from the server, note this is 
all happening in the coroutine and the top-level code doesn’t wait for it.</p>

<p>Can we pass the results back from the nested tasks to the top level and wait for them at the end? 
Yes! Tokio provides its own, async implementation of a communication channel. 
Let’s setup a channel, plug its sending side to the coroutine and receive at the top-level at the end, 
but before computing the end time:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">let</span> <span class="n">start</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
    <span class="k">let</span> <span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="k">mut</span> <span class="n">rx</span><span class="p">)</span> <span class="o">=</span> <span class="nn">tokio</span><span class="p">::</span><span class="nn">sync</span><span class="p">::</span><span class="nn">mpsc</span><span class="p">::</span><span class="nf">unbounded_channel</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">session</span> <span class="o">=</span> <span class="nn">Arc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">session</span><span class="p">);</span>
    <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">count</span> <span class="p">{</span>
        <span class="k">let</span> <span class="k">mut</span> <span class="n">statement</span> <span class="o">=</span> <span class="n">statement</span><span class="nf">.bind</span><span class="p">();</span>
        <span class="n">statement</span><span class="nf">.bind</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span> <span class="k">as</span> <span class="nb">i64</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>

        <span class="k">let</span> <span class="n">session</span> <span class="o">=</span> <span class="n">session</span><span class="nf">.clone</span><span class="p">();</span>
        <span class="k">let</span> <span class="n">tx</span> <span class="o">=</span> <span class="n">tx</span><span class="nf">.clone</span><span class="p">();</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nf">spawn</span><span class="p">(</span><span class="k">async</span> <span class="k">move</span> <span class="p">{</span>
            <span class="k">let</span> <span class="n">query_start</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
            <span class="k">let</span> <span class="n">result</span> <span class="o">=</span> <span class="n">session</span><span class="nf">.execute</span><span class="p">(</span><span class="o">&amp;</span><span class="n">statement</span><span class="p">);</span>
            <span class="n">result</span><span class="py">.await</span><span class="nf">.unwrap</span><span class="p">();</span>
            <span class="k">let</span> <span class="n">query_end</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
            <span class="k">let</span> <span class="n">duration_micros</span><span class="o">=</span> <span class="p">(</span><span class="n">query_end</span> <span class="o">-</span> <span class="n">query_start</span><span class="p">)</span><span class="nf">.as_micros</span><span class="p">();</span>
            <span class="n">tx</span><span class="nf">.send</span><span class="p">(</span><span class="n">duration_micros</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
        <span class="p">});</span>
    <span class="p">}</span>   
    <span class="c">// We need to drop the top-level tx we created at the beginning,</span>
    <span class="c">// so all txs are dropped when all queries finish. </span>
    <span class="c">// Otherwise the following read loop would wait for more data forever.</span>
    <span class="k">drop</span><span class="p">(</span><span class="n">tx</span><span class="p">);</span>

    <span class="k">let</span> <span class="k">mut</span> <span class="n">successful_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">while</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">duration</span><span class="p">)</span> <span class="o">=</span> <span class="n">rx</span><span class="nf">.next</span><span class="p">()</span><span class="py">.await</span> <span class="p">{</span>
        <span class="c">// Here we get a sequence of durations</span>
        <span class="c">// We could use it also to compute e.g. the mean duration or the histogram</span>
        <span class="n">successful_count</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">let</span> <span class="n">end</span> <span class="o">=</span> <span class="nn">Instant</span><span class="p">::</span><span class="nf">now</span><span class="p">();</span>
    <span class="nd">println!</span><span class="p">(</span>
        <span class="s">"Throughput: {:.1} request/s"</span><span class="p">,</span>
        <span class="mf">1000000.0</span> <span class="o">*</span> <span class="n">successful_count</span> <span class="k">as</span> <span class="nb">f64</span> <span class="o">/</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="nf">.as_micros</span><span class="p">()</span> <span class="k">as</span> <span class="nb">f64</span>
    <span class="p">);</span>

</code></pre></div></div>

<p>This prints a much more accurate number:</p>
<pre>
Throughput: 91734.7 request/s
</pre>

<p>Can we now increase the count back to 100,000?
Not yet. Although we’re waiting at the end, the loop still spins like crazy submitting all the
queries at once and overflowing the queues. We need to slow it down.</p>

<h1 id="backpressure">Backpressure</h1>
<p>We don’t want to exceed the capacity of the internal queues of the driver.
Hence, we need to keep the number of submitted but unfinished queries limited.
This is a good task for a semaphore. A semaphore is a structure that allows at most
N parallel tasks. Tokio comes with a nice, asynchronous implementation of semaphore.
The <code class="language-plaintext highlighter-rouge">Semaphore</code> structure allows a limited number of permits. The function of obtaining
a permit is asynchronous, so it composes with the other elements we already use here.
We’ll obtain a permit before spawning a task, and drop the permit after receiving the
results.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c">// ...</span>
    <span class="k">let</span> <span class="n">parallelism_limit</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">semaphore</span> <span class="o">=</span> <span class="nn">Arc</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">Semaphore</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">parallelism_limit</span><span class="p">));</span>
    <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">count</span> <span class="p">{</span>
        <span class="c">// ...</span>
        <span class="k">let</span> <span class="n">permit</span> <span class="o">=</span> <span class="n">semaphore</span><span class="nf">.clone</span><span class="p">()</span><span class="nf">.acquire_owned</span><span class="p">()</span><span class="py">.await</span><span class="p">;</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nf">spawn</span><span class="p">(</span><span class="k">async</span> <span class="k">move</span> <span class="p">{</span>
            <span class="c">// ... run the query and await the result</span>

            <span class="c">// Now drop the permit; </span>
            <span class="c">// Actually it is sufficient to reference the permit value </span>
            <span class="c">// anywhere inside the coroutine so it is moved here and it would be dropped</span>
            <span class="c">// automatically at the closing brace. But drop is more explicitly </span>
            <span class="c">// telling the intent.</span>
            <span class="k">drop</span><span class="p">(</span><span class="n">permit</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">});</span>
    <span class="c">// ...</span>

</code></pre></div></div>
<p>Because the permit is passed to the asynchronous code that may outlive the
scope of main, here again we need to use <code class="language-plaintext highlighter-rouge">Arc</code>. We also needed to use an owned permit,
rather than the standard one obtained by <code class="language-plaintext highlighter-rouge">acquire()</code>. 
An owned permit can be moved, a standard one cannot.</p>

<p>After putting it all together, and running the benchmark for a few times to warmup the server, 
the final throughput of running 100k queries was:</p>
<pre>
Throughput: 152374.3 request/s
</pre>

<h1 id="the-final-word">The Final Word</h1>
<p>Benchmarking is hard and it is easy to get 
incorrect results or arrive at incorrect conclusions.</p>

<p>Keep in mind that the way how you query data may severly affect the numbers you get.
Watch for:</p>
<ul>
  <li>Parallelism levels</li>
  <li>Number of connections / threads</li>
  <li>Coordinated omission</li>
  <li>Caching effects</li>
  <li>JVM warmup effects</li>
  <li>Data sizes (does the query even return any results?)</li>
  <li>Waiting for all the stuff to actually finish before reading the wall clock time</li>
  <li>Using the available database features (e.g. prepared statements)</li>
  <li>Queue size limits / backpressure</li>
  <li>CPU and other resources consumed by the benchmarking program</li>
</ul>

<p>If you’d like to measure performance of your Cassandra cluster, 
you should try the tool I’m working on at the moment: 
<a href="https://github.com/pkolaczk/latte">Latte</a>. 
Latte uses uses the approach described in this blog post to measure 
the throughput and response times. It is still very early-stage and 
I look forward to your feedback!</p>

  

<style>
#share-buttons { margin-top: 2em; }
#share-buttons > a {   
    display: inline-block;
    vertical-align: baseline;
}
#share-buttons > a > svg { 
    height: 1.2em; 
    width: 1.2em; 
    margin-left: .25em; 
    margin-right: .25em; 
    fill: gray; 
    position: relative; 
    top: .17em; 
}
#share-buttons > span { 
    margin-right: .4em 
}
#share-buttons > a:hover {cursor: pointer;}
#share-buttons > a.facebook:hover > svg {fill: #3B5998;}
#share-buttons > a.twitter:hover > svg {fill: #55ACEE;}
#share-buttons > a.linkedin:hover > svg {fill: #0077b5;}
#share-buttons > a.pinterest:hover > svg {fill: #CB2027;}
#share-buttons > a.mail:hover > svg {fill: #0077b5; }
</style>

<div id="share-buttons">
    <span style="color: gray;">Share on:</span>
    <a class="facebook" title="Share this on Facebook" href="http://www.facebook.com/share.php?u=/benchmarking-cassandra/" target="_blank"> 
        <svg><use xlink:href="/assets/fontawesome/icons.svg#facebook"></use></svg>
    </a>
    <a class="twitter" title="Share this on Twitter" href="https://twitter.com/intent/tweet?text=/benchmarking-cassandra/" target="_blank">
        <svg><use xlink:href="/assets/fontawesome/icons.svg#twitter"></use></svg>
    </a>
    <a class="linkedin" title="Share this on Linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=/benchmarking-cassandra/" target="_blank">
        <svg><use xlink:href="/assets/fontawesome/icons.svg#linkedin"></use></svg>
    </a>
    <a class="mail" title="Share this through Email" href="mailto:?&body=/benchmarking-cassandra/">
        <svg><use xlink:href="/assets/fontawesome/icons.svg#envelope"></use></svg>
    </a>
</div>

  
    <hr>
    
        
      <div id="disqus_thread"></div>
      <script src="/assets/disqus/disqusloader.js"></script>
      <script>        
        disqusLoader('#disqus_thread', { scriptUrl: "//pkolaczk.disqus.com/embed.js" });
      </script> 
    
    <noscript>Please enable JavaScript to view comments.</noscript>
  
</article>


  <footer class="related">
    <div class="previous"><span>Previous Post</span><a href="/in-defense-of-switch/">In Defense of a Switch</a></div>
    <div class="next"><span>Next Post</span><a href="/benchmarking-cassandra-with-rust-streams/">Scalable Benchmarking with Rust Streams</a></div>
  </footer>


</body>
</html>
